{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trying out GNN using graph convolutional network architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\rohil\\anaconda3\\lib\\site-packages (2.0.1)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\rohil\\anaconda3\\lib\\site-packages (from torch) (4.4.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\rohil\\anaconda3\\lib\\site-packages (from torch) (1.11.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\rohil\\anaconda3\\lib\\site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\rohil\\anaconda3\\lib\\site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\rohil\\anaconda3\\lib\\site-packages (from torch) (3.9.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\rohil\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\rohil\\anaconda3\\lib\\site-packages (from sympy->torch) (1.2.1)\n",
      "Requirement already satisfied: torch_geometric in c:\\users\\rohil\\anaconda3\\lib\\site-packages (2.4.0)\n",
      "Requirement already satisfied: pyparsing in c:\\users\\rohil\\anaconda3\\lib\\site-packages (from torch_geometric) (3.0.9)\n",
      "Requirement already satisfied: numpy in c:\\users\\rohil\\anaconda3\\lib\\site-packages (from torch_geometric) (1.23.5)\n",
      "Requirement already satisfied: scipy in c:\\users\\rohil\\anaconda3\\lib\\site-packages (from torch_geometric) (1.12.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\rohil\\anaconda3\\lib\\site-packages (from torch_geometric) (1.2.1)\n",
      "Requirement already satisfied: psutil>=5.8.0 in c:\\users\\rohil\\anaconda3\\lib\\site-packages (from torch_geometric) (5.9.0)\n",
      "Requirement already satisfied: requests in c:\\users\\rohil\\anaconda3\\lib\\site-packages (from torch_geometric) (2.28.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\rohil\\anaconda3\\lib\\site-packages (from torch_geometric) (3.1.2)\n",
      "Requirement already satisfied: tqdm in c:\\users\\rohil\\anaconda3\\lib\\site-packages (from torch_geometric) (4.64.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\rohil\\anaconda3\\lib\\site-packages (from jinja2->torch_geometric) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\rohil\\anaconda3\\lib\\site-packages (from requests->torch_geometric) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\rohil\\anaconda3\\lib\\site-packages (from requests->torch_geometric) (2022.12.7)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\rohil\\anaconda3\\lib\\site-packages (from requests->torch_geometric) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\rohil\\anaconda3\\lib\\site-packages (from requests->torch_geometric) (1.26.14)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\rohil\\anaconda3\\lib\\site-packages (from scikit-learn->torch_geometric) (2.2.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\rohil\\anaconda3\\lib\\site-packages (from scikit-learn->torch_geometric) (1.1.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\rohil\\anaconda3\\lib\\site-packages (from tqdm->torch_geometric) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch\n",
    "!pip install torch_geometric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.datasets import Planetoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Planetoid(root='/tmp/Cora', name='Cora')\n",
    "graph = dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[2708, 1433], edge_index=[2, 10556], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2708, 1433])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To visualise the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from torch_geometric.utils import to_networkx\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_networkx(graph, n_sample=None):\n",
    "\n",
    "    g = to_networkx(graph, node_attrs=[\"x\"])\n",
    "    y = graph.y.numpy()\n",
    "\n",
    "    if n_sample is not None:\n",
    "        sampled_nodes = random.sample(g.nodes, n_sample)\n",
    "        g = g.subgraph(sampled_nodes)\n",
    "        y = y[sampled_nodes]\n",
    "\n",
    "    return g, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_graph(g, y):\n",
    "\n",
    "    plt.figure(figsize=(9, 7))\n",
    "    nx.draw_spring(g, node_size=30, arrows=False, node_color=y)\n",
    "    plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'convert_to_networkx' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m g, y \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_to_networkx\u001b[49m(graph, n_sample\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m)\n\u001b[0;32m      2\u001b[0m plot_graph(g, y)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'convert_to_networkx' is not defined"
     ]
    }
   ],
   "source": [
    "g, y = convert_to_networkx(graph, n_sample=1000)\n",
    "plot_graph(g, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch_geometric.transforms as T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split into train and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = T.RandomNodeSplit(num_val=0.1, num_test=0.2)\n",
    "graph = split(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[2708, 1433], edge_index=[2, 10556], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2708, 1433])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Declare the basic MLP in PyTorch to which we shall feed the graph embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "        nn.Linear(dataset.num_node_features, 64),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(64, 32),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(32, dataset.num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, data):\n",
    "        x = data.x  # only using node features (x)\n",
    "        output = self.layers(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Declare the training and testing function for the base MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_node_classifier(model, graph, mask):\n",
    "\n",
    "    model.eval()\n",
    "    pred = model(graph).argmax(dim=1)\n",
    "    correct = (pred[mask] == graph.y[mask]).sum()\n",
    "    acc = int(correct) / int(mask.sum())\n",
    "\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_node_classifier(model, graph, optimizer, criterion, n_epochs=200):\n",
    "\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        out = model(graph)\n",
    "        loss = criterion(out[graph.train_mask], graph.y[graph.train_mask])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        pred = out.argmax(dim=1)\n",
    "        acc = eval_node_classifier(model, graph, graph.val_mask)\n",
    "\n",
    "        if epoch % 10 == 0:\n",
    "            print(f'Epoch: {epoch:03d}, Train Loss: {loss:.3f}, Val Acc: {acc:.3f}')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lets simply use the X values of just words and run the normal feed forward MLP to see the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "mlp = MLP().to(device)\n",
    "optimizer_mlp = torch.optim.Adam(mlp.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 010, Train Loss: 0.934, Val Acc: 0.679\n",
      "Epoch: 020, Train Loss: 0.103, Val Acc: 0.738\n",
      "Epoch: 030, Train Loss: 0.018, Val Acc: 0.705\n",
      "Epoch: 040, Train Loss: 0.012, Val Acc: 0.701\n",
      "Epoch: 050, Train Loss: 0.013, Val Acc: 0.701\n",
      "Epoch: 060, Train Loss: 0.012, Val Acc: 0.708\n",
      "Epoch: 070, Train Loss: 0.010, Val Acc: 0.708\n",
      "Epoch: 080, Train Loss: 0.010, Val Acc: 0.712\n",
      "Epoch: 090, Train Loss: 0.009, Val Acc: 0.716\n",
      "Epoch: 100, Train Loss: 0.008, Val Acc: 0.716\n",
      "Epoch: 110, Train Loss: 0.008, Val Acc: 0.720\n",
      "Epoch: 120, Train Loss: 0.007, Val Acc: 0.723\n",
      "Epoch: 130, Train Loss: 0.007, Val Acc: 0.727\n",
      "Epoch: 140, Train Loss: 0.007, Val Acc: 0.727\n",
      "Epoch: 150, Train Loss: 0.007, Val Acc: 0.723\n"
     ]
    }
   ],
   "source": [
    "mlp = train_node_classifier(mlp, graph, optimizer_mlp, criterion, n_epochs=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_for_mlp = mlp(graph).argmax(dim = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_for_mlp = graph.test_mask\n",
    "\n",
    "correct_preds_for_mlp = (output_for_mlp[mask_for_mlp] == graph.y[mask_for_mlp]).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7491)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_preds_for_mlp/output_for_mlp[mask_for_mlp].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Acc: 0.749\n"
     ]
    }
   ],
   "source": [
    "test_acc = eval_node_classifier(mlp, graph, graph.test_mask)\n",
    "print(f'Test Acc: {test_acc:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import GCNConv\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(dataset.num_node_features, 16)\n",
    "        self.conv2 = GCNConv(16, dataset.num_classes)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        output = self.conv2(x, edge_index)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 010, Train Loss: 0.889, Val Acc: 0.808\n",
      "Epoch: 020, Train Loss: 0.366, Val Acc: 0.875\n",
      "Epoch: 030, Train Loss: 0.223, Val Acc: 0.871\n",
      "Epoch: 040, Train Loss: 0.171, Val Acc: 0.871\n",
      "Epoch: 050, Train Loss: 0.147, Val Acc: 0.867\n",
      "Epoch: 060, Train Loss: 0.136, Val Acc: 0.863\n",
      "Epoch: 070, Train Loss: 0.128, Val Acc: 0.867\n",
      "Epoch: 080, Train Loss: 0.120, Val Acc: 0.863\n",
      "Epoch: 090, Train Loss: 0.113, Val Acc: 0.863\n",
      "Epoch: 100, Train Loss: 0.106, Val Acc: 0.871\n",
      "Epoch: 110, Train Loss: 0.101, Val Acc: 0.867\n",
      "Epoch: 120, Train Loss: 0.096, Val Acc: 0.871\n",
      "Epoch: 130, Train Loss: 0.092, Val Acc: 0.871\n",
      "Epoch: 140, Train Loss: 0.089, Val Acc: 0.867\n",
      "Epoch: 150, Train Loss: 0.086, Val Acc: 0.863\n",
      "Epoch: 160, Train Loss: 0.083, Val Acc: 0.863\n",
      "Epoch: 170, Train Loss: 0.081, Val Acc: 0.863\n",
      "Epoch: 180, Train Loss: 0.079, Val Acc: 0.863\n",
      "Epoch: 190, Train Loss: 0.077, Val Acc: 0.863\n",
      "Epoch: 200, Train Loss: 0.075, Val Acc: 0.860\n"
     ]
    }
   ],
   "source": [
    "gcn = GCN().to(device)\n",
    "optimizer_gcn = torch.optim.Adam(gcn.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "gcn = train_node_classifier(gcn, graph, optimizer_gcn, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Acc: 0.893\n"
     ]
    }
   ],
   "source": [
    "test_acc = eval_node_classifier(gcn, graph, graph.test_mask)\n",
    "print(f'Test Acc: {test_acc:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
